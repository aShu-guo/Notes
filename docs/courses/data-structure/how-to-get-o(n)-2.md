# 最好、最坏情况时间复杂度

之前讲了基本的复杂度分析[算法复杂度分析之：如何分析、统计算法的执行效率和资源消耗？](<./how-to-get-o(n)-1.md>)

这篇文章会继续给讲四个复杂度分析方面的知识点

- **最好情况时间复杂度**（best case time complexity）
- **最坏情况时间复杂度**（worst case time complexity）
- **平均情况时间复杂度**（average case time complexity）
- **均摊时间复杂度**（amortized time complexity）。

首先可以看下下面这个例子：

```js
function find(array, n, x) {
  let i = 0;
  let pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
      pos = i;
      break;
    }
  }
  return pos;
}
```

这段代码要实现的功能是，在一个无序的数组（array）中，查找变量 x 出现的位置。如果没有找到，就返回 -1。那么这段代码的时间复杂度是O(n)吗？下面我们来解答一下。

因为，要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查找的变量 x，那就不需要继续遍历剩下的 n-1 个数据了，那时间复杂度就是 O(1)。但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。所以，不同的情况下，这段代码的时间复杂度是不一样的。

为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：

- `最好`情况时间复杂度
- `最坏`情况时间复杂度
- `平均`情况时间复杂度。

**最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度**。

就像我们刚刚讲到的，在最理想的情况下，要查找的变量 x 正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度。

**最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度**。

就像刚举的那个例子，如果数组中没有要查找的变量 x，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度。

## 平均情况时间复杂度

最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，我们需要引入另一个概念：**平均情况时间复杂度**

借助刚才查找变量 x 的例子来解释

要查找的变量 x 在数组中的位置，有 n+1 种情况：**在数组的 0～n-1 位置中和不在数组中**。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即：

![img.png](</imgs/computes-course/data-structure/how-to-get-o(1).png>)

我们知道，时间复杂度的大 O 标记法中，可以省略掉`系数`、`低阶`、`常量`，所以，咱们把刚刚这个公式简化之后，得到的平均时间复杂度就是 O(n)。

这个结论虽然是正确的，但是计算过程稍微有点儿问题。究竟是什么问题呢？我们刚讲的这 n+1 种情况，出现的概率并不是一样的。我带你具体分析一下。（这里要稍微用到一点儿概率论的知识，不过非常简单，你不用担心。）

我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，为了方便你理解，我们假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。

因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样：

![img.png](</imgs/computes-course/data-structure/how-to-get-o(1)-1.png>)

引入概率之后，前面那段代码的加权平均值为 (3n+1)/4。用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)。

你可能会说，平均时间复杂度分析好复杂啊，还要涉及概率论的知识。实际上，**在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况**。像我们上一节课举的那些例子那样，很多时候，我们使用一个复杂度就可以满足需求了。**只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分**。

## 均摊时间复杂度

均摊时间复杂度，听起来跟平均时间复杂度有点儿像，这两个概念确实非常容易弄混。前面说了，大部分情况下，我们并不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而**均摊时间复杂度应用的场景比它更加特殊、更加有限**。

首先可以看下下面这个例子：

```c++
    // array 表示一个长度为 n 的数组
    // 代码中的 array.length 就等于 n
    int[] array = new int[n];
    int count = 0;
    void insert(int val) {
        if (count == array.length) {
            int sum = 0;
            for (int i = 0; i < array.length; ++i) { sum = sum + array[i]; }
            array[0] = sum;
            count = 1;
        }
        array[count] = val;
        ++count;
    }
```

先来解释一下这段代码。这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 count == array.length 时，我们用 for 循环遍历数组求和，并清空数组，将求和之后的 sum 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。

那这段代码的时间复杂度是多少呢？你可以先用我们刚讲到的三种时间复杂度的分析方法来分析一下。

最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 count 的位置就可以了，所以**最好情况时间复杂度为 O(1)**。最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以**最坏情况时间复杂度为 O(n)**。

那平均时间复杂度是多少呢？**答案是 O(1)**。还是可以通过前面讲的概率论的方法来分析。

假设数组的长度是 n，根据数据插入的位置的不同，我们可以分为 n 种情况，每种情况的时间复杂度是 O(1)。除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 O(n)。而且，这 n+1 种情况发生的概率一样，都是 1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：

![img.png](</imgs/computes-course/data-structure/how-to-get-o(1)-2.png>)

- find() 函数在**极端情况下**，复杂度才为 O(1)。但 insert() 在**大部分情况下**，时间复杂度都为 O(1)。只有个别情况下，复杂度才比较高，为 O(n)。这是 insert()第一个区别于 find() 的地方。

- 对于 insert() 函数来说，O(1) 时间复杂度的插入和 O(n) 时间复杂度的插入，出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个 O(n) 插入之后，紧跟着 n-1 个 O(1) 的插入操作，循环往复。

所以，针对这样一种特殊场景的复杂度分析，我们并不需要像之前讲平均复杂度分析方法那样，找出所有的输入情况及相应的发生概率，然后再计算加权平均值。

针对这种特殊的场景，我们引入了一种更加简单的分析方法：**摊还分析法，通过摊还分析得到的时间复杂度我们起了一个名字，叫均摊时间复杂度**。

### 究竟如何使用摊还分析法来分析算法的均摊时间复杂度呢？

还是继续看在数组中插入数据的这个例子。每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。这就是均摊分析的大致思路。

**对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上**。而且，在能够应用均摊时间复杂度分析的场合，**一般均摊时间复杂度就等于最好情况时间复杂度**。

可以认为，**均摊时间复杂度就是一种特殊的平均时间复杂度**。

本文转自 <https://juejin.cn/post/6938373568782663711>，如有侵权，请联系删除。
